#–î–æ–±–∞–≤–ª–µ–Ω–æ —Å–æ–ø—Ä—è–∂–µ–Ω–∏–µ —Å ChromaDB –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ RAG

import gradio as gr
from llama_cpp import Llama
import time
import chromadb
from chromadb.utils import embedding_functions
import datetime
import warnings

warnings.filterwarnings("ignore", category=UserWarning, module="gradio.chat_interface")

print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Saiga Assistant...")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB
client = chromadb.PersistentClient(path="./chroma_memory_db")
embed_func = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="intfloat/multilingual-e5-small")
collection = client.get_or_create_collection(
    name="saiga_memory",
    embedding_function=embed_func,
    metadata={"hnsw:space": "cosine"}
)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
llm = Llama(
    model_path="/home/dragon/ai_assistant/saiga-7b-Q4_K_M/saiga-7b-Q4_K_M.gguf",
    n_ctx=2048,
    n_threads=6,
    n_batch=512,
    verbose=False
)

print("‚úÖ –ú–æ–¥–µ–ª—å –∏ –ë–î –≥–æ—Ç–æ–≤—ã!")

def chat_with_saiga(message, history):
    print(f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {message}")
    
    # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∞–Ω—Ç–∏-–º—É—Å–æ—Ä–æ–º
    system_prompt = "–¢—ã ‚Äî –ø—Ä—è–º–æ–ª–∏–Ω–µ–π–Ω—ã–π —á—É–≤–∞–∫, –∫–∞–∫ —è: –æ—Ç–≤–µ—á–∞–π —á–µ—Å—Ç–Ω–æ, –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã, –±–µ–∑ –ø–æ–¥–ª–∏–∑—ã–≤–∞–Ω–∏—è. –ú–∞–Ω–µ—Ä–∞: –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω–∞—è, —Å '–±—Ä–æ' –∏ '—á—É–≤–∞–∫'. –ï—Å–ª–∏ –¥–µ—Ä—å–º–æ ‚Äî —Å–∫–∞–∂–∏ –ø—Ä—è–º–æ. –ù–µ –≤—ã–≤–æ–¥–∏ –¥–∞—Ç—ã, '–î–∞—Ç–∞:' –∏–ª–∏ '–ü—Ä–æ—à–ª–æ–µ:' –≤ –æ—Ç–≤–µ—Ç–µ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –º—ã—à–ª–µ–Ω–∏—è, —Å—É–º–º–∏—Ä—É–π –ø–æ —Å—É—Ç–∏. –ü—Ä–∏–º–µ—Ä: –µ—Å–ª–∏ –≥–æ–≤–æ—Ä—è—Ç '–ü—Ä–µ–≤–µ–¥, –º–µ–¥–≤–µ–¥!', –æ—Ç–≤–µ—á–∞–π '–ü—Ä–µ–≤–µ–¥, –∫—Ä–æ—Å–∞—Ñ—á–µ–≥!'."
    
    # –ö–æ—Ä–æ—Ç–∫–∏–π history: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2, —á—Ç–æ–± –Ω–µ –∑–∞—Ü–∏–∫–ª–∏–≤–∞—Ç—å—Å—è
    short_history = "\n".join([h['content'] for h in history[-2:] if 'content' in h])
    
    # –ü–æ–∏—Å–∫ –≤ –ë–î: —Ç–æ–ø-2 (–º–µ–Ω—å—à–µ, —á—Ç–æ–± –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å)
    current_time = time.time()
    five_min_ago = current_time - 300
    results = collection.query(
        query_texts=[message],
        n_results=2,  # –£–º–µ–Ω—å—à–∏–ª–∏ –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã
        where={"timestamp": {"$lt": five_min_ago}}
    )
    context = ""
    if results['documents'] and results['documents'][0]:
        # –°—É–º–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç, —á—Ç–æ–± –Ω–µ –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –¥–æ—Å–ª–æ–≤–Ω–æ
        context = " ".join([doc.split('\n')[1].replace("–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: ", "") for doc in results['documents'][0]])  # –¢–æ–ª—å–∫–æ —Å—É—Ç—å –æ—Ç–≤–µ—Ç–∞
        print(f"DEBUG: –°—É–º–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {context}")
    
    # –î–ª—è "–≥–æ–¥ –Ω–∞–∑–∞–¥" (—Å—É–º–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
    if "–≥–æ–¥ –Ω–∞–∑–∞–¥" in message.lower():
        year_ago = current_time - 31536000
        results = collection.query(
            query_texts=[message],
            n_results=2,
            where={"timestamp": {"$gt": year_ago - 86400, "$lt": year_ago + 86400}}
        )
        context = " ".join([doc.split('\n')[1].replace("–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: ", "") for doc in results['documents'][0]]) if results['documents'] else "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–µ–ª –≥–æ–¥ –Ω–∞–∑–∞–¥, —á—É–≤–∞–∫."
        print(f"DEBUG: –°—É–º–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥–æ–¥ –Ω–∞–∑–∞–¥: {context}")

    full_message = f"{system_prompt}\n\n–ö–æ—Ä–æ—Ç–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞: {short_history}\n\n–°—É–º–º–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ—à–ª–∞—è –∏—Å—Ç–æ—Ä–∏—è: {context}\n\n–í–æ–ø—Ä–æ—Å: {message}\n\n–û—Ç–≤–µ—Ç:"
    
    start_time = time.time()
    response = llm(
        full_message,
        max_tokens=200,  # –ë–∞–ª–∞–Ω—Å: –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –ø–æ–ª–Ω—ã—Ö, –±–µ–∑ –±–µ–∑—É–º–∏—è
        temperature=0.5,  # –î–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        stop=["\n\n"],  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π, —á—Ç–æ–± –Ω–µ –æ–±—Ä—É–±–∞–ª–æ
        echo=False,  # –ë–µ–∑ —ç—Ö–∞ –ø—Ä–æ–º–ø—Ç–∞
        repeat_penalty=1.5  # –°–∏–ª—å–Ω—ã–π —à—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä—ã
    )
    response_time = time.time() - start_time
    answer = response['choices'][0]['text'].strip()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ (—Ç–æ–ª—å–∫–æ —Å—É—Ç—å, –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ)
    doc_id = f"msg_{int(current_time)}"
    current_date = datetime.datetime.fromtimestamp(current_time).strftime("%Y-%m-%d")
    collection.add(
        documents=[answer],  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç, —á—Ç–æ–± –Ω–µ –∑–∞—Å–æ—Ä—è—Ç—å –ë–î
        metadatas=[{"date": current_date, "timestamp": int(current_time), "user": "you", "original_message": message}],
        ids=[doc_id]
    )
    
    print(f"ü§ñ Saiga ({response_time:.1f}—Å): {answer}")
    return answer

# Gradio
interface = gr.ChatInterface(
    chat_with_saiga,
    chatbot=gr.Chatbot(type="messages", height=800),
    title="ü§ñ Saiga Assistant —Å ChromaDB",
    description="–†—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –ò–ò —Å –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç—å—é"
)

print("üåê –ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞...")
print("üì± –û—Ç–∫—Ä–æ–π—Ç–µ –≤ –±—Ä–∞—É–∑–µ—Ä–µ: http://localhost:7861")

interface.launch(
    server_name="0.0.0.0",
    server_port=7861,
    share=False
)